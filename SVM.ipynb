{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10eb7d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T01:19:34.727464Z",
     "iopub.status.busy": "2024-03-19T01:19:34.726779Z",
     "iopub.status.idle": "2024-03-19T01:19:35.301271Z",
     "shell.execute_reply": "2024-03-19T01:19:35.300628Z"
    }
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "# Support vector machines (SVMs) are a set of supervised learning methods used for \n",
    "# classification, regression and outliers detection.\n",
    "\n",
    "# The advantages of support vector machines are:\n",
    "    # Effective in high dimensional spaces.\n",
    "    # Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "    # Uses a subset of training points in the decision function (called support vectors), \n",
    "    # so it is also memory efficient.\n",
    "    # Versatile: different Kernel functions can be specified for the decision function. \n",
    "    # Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "# The disadvantages of support vector machines include:\n",
    "    # If the number of features is much greater than the number of samples, avoid over-fitting \n",
    "    # in choosing Kernel functions and regularization term is crucial.\n",
    "    # SVMs do not directly provide probability estimates, these are calculated using an \n",
    "    # expensive five-fold cross-validation (see Scores and probabilities, below).\n",
    "\n",
    "# class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', \n",
    "# coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, \n",
    "# class_weight=None, verbose=False, max_iter=-1, \n",
    "# decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c89a952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T01:19:35.304068Z",
     "iopub.status.busy": "2024-03-19T01:19:35.303737Z",
     "iopub.status.idle": "2024-03-19T01:19:43.966014Z",
     "shell.execute_reply": "2024-03-19T01:19:43.965367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train :  0.8222222222222222\n",
      "accuracy test :  0.6888888888888889\n",
      "predicted probabilities:\n",
      " [[0.735 0.265]\n",
      " [0.368 0.632]\n",
      " [0.277 0.723]\n",
      " [0.392 0.608]\n",
      " [0.376 0.624]\n",
      " [0.364 0.636]\n",
      " [0.170 0.830]\n",
      " [0.672 0.328]\n",
      " [0.430 0.570]\n",
      " [0.225 0.775]\n",
      " [0.642 0.358]\n",
      " [0.261 0.739]\n",
      " [0.447 0.553]\n",
      " [0.784 0.216]\n",
      " [0.274 0.726]\n",
      " [0.606 0.394]\n",
      " [0.293 0.707]\n",
      " [0.453 0.547]\n",
      " [0.442 0.558]\n",
      " [0.669 0.331]\n",
      " [0.178 0.822]\n",
      " [0.395 0.605]\n",
      " [0.725 0.275]\n",
      " [0.625 0.375]\n",
      " [0.500 0.500]\n",
      " [0.861 0.139]\n",
      " [0.585 0.415]\n",
      " [0.251 0.749]\n",
      " [0.778 0.222]\n",
      " [0.557 0.443]\n",
      " [0.685 0.315]\n",
      " [0.464 0.536]\n",
      " [0.710 0.290]\n",
      " [0.227 0.773]\n",
      " [0.184 0.816]\n",
      " [0.386 0.614]\n",
      " [0.819 0.181]\n",
      " [0.713 0.287]\n",
      " [0.510 0.490]\n",
      " [0.167 0.833]\n",
      " [0.769 0.231]\n",
      " [0.479 0.521]\n",
      " [0.300 0.700]\n",
      " [0.575 0.425]\n",
      " [0.601 0.399]\n",
      " [0.199 0.801]\n",
      " [0.575 0.425]\n",
      " [0.716 0.284]\n",
      " [0.784 0.216]\n",
      " [0.732 0.268]\n",
      " [0.094 0.906]\n",
      " [0.103 0.897]\n",
      " [0.745 0.255]\n",
      " [0.420 0.580]\n",
      " [0.644 0.356]\n",
      " [0.525 0.475]\n",
      " [0.567 0.433]\n",
      " [0.381 0.619]\n",
      " [0.157 0.843]\n",
      " [0.308 0.692]\n",
      " [0.500 0.500]\n",
      " [0.285 0.715]\n",
      " [0.252 0.748]\n",
      " [0.682 0.318]\n",
      " [0.650 0.350]\n",
      " [0.320 0.680]\n",
      " [0.833 0.167]\n",
      " [0.585 0.415]\n",
      " [0.493 0.507]\n",
      " [0.793 0.207]\n",
      " [0.506 0.494]\n",
      " [0.557 0.443]\n",
      " [0.175 0.825]\n",
      " [0.299 0.701]\n",
      " [0.614 0.386]\n",
      " [0.583 0.417]\n",
      " [0.535 0.465]\n",
      " [0.610 0.390]\n",
      " [0.292 0.708]\n",
      " [0.411 0.589]\n",
      " [0.340 0.660]\n",
      " [0.633 0.367]\n",
      " [0.585 0.415]\n",
      " [0.396 0.604]\n",
      " [0.154 0.846]\n",
      " [0.573 0.427]\n",
      " [0.816 0.184]\n",
      " [0.613 0.387]\n",
      " [0.223 0.777]\n",
      " [0.603 0.397]\n",
      " [0.585 0.415]\n",
      " [0.387 0.613]\n",
      " [0.303 0.697]\n",
      " [0.538 0.462]\n",
      " [0.220 0.780]\n",
      " [0.168 0.832]\n",
      " [0.710 0.290]\n",
      " [0.285 0.715]\n",
      " [0.611 0.389]\n",
      " [0.156 0.844]\n",
      " [0.884 0.116]\n",
      " [0.700 0.300]\n",
      " [0.554 0.446]\n",
      " [0.513 0.487]\n",
      " [0.384 0.616]\n",
      " [0.286 0.714]\n",
      " [0.702 0.298]\n",
      " [0.534 0.466]\n",
      " [0.318 0.682]\n",
      " [0.422 0.578]\n",
      " [0.274 0.726]\n",
      " [0.126 0.874]\n",
      " [0.532 0.468]\n",
      " [0.338 0.662]\n",
      " [0.596 0.404]\n",
      " [0.538 0.462]\n",
      " [0.664 0.336]\n",
      " [0.270 0.730]\n",
      " [0.541 0.459]\n",
      " [0.456 0.544]\n",
      " [0.725 0.275]\n",
      " [0.590 0.410]\n",
      " [0.521 0.479]\n",
      " [0.489 0.511]\n",
      " [0.482 0.518]\n",
      " [0.367 0.633]\n",
      " [0.522 0.478]\n",
      " [0.638 0.362]\n",
      " [0.697 0.303]\n",
      " [0.617 0.383]\n",
      " [0.393 0.607]\n",
      " [0.812 0.188]\n",
      " [0.739 0.261]\n",
      " [0.303 0.697]\n",
      " [0.194 0.806]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values\n",
    "    ('scaler', StandardScaler())  # Scale the features\n",
    "])\n",
    "\n",
    "##############################  TRAINING  ##############################################\n",
    "# data\n",
    "input_data = pd.read_csv('NHANES_data_stroke_train.csv')\n",
    "\n",
    "#under sample the non-stroke\n",
    "MI_positive = input_data[input_data['stroke'] == 1]\n",
    "MI_negitive = input_data[input_data['stroke'] == 2].sample(frac=.03411675511751327)\n",
    "input_data = pd.concat([MI_positive, MI_negitive])\n",
    "\n",
    "# attributes\n",
    "featurenames = [\"Income\",\"Sex\",\"Age\",\"Race\",\"Edu\",\"Diastolic\",\"Systolic\",\"Pulse\",\"BMI\",\"HDL\",\"Trig\",\"LDL\",\"TCHOL\",\"kidneys_eGFR\",\"Diabetes\",\"CurrentSmoker\",\"isActive\",\"isInsured\"]\n",
    "X = input_data[featurenames]\n",
    "y = input_data['stroke']\n",
    "\n",
    "# impute and scale the data\n",
    "X = preprocessing_pipeline.fit_transform(X)\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.50, random_state=42)\n",
    "\n",
    "# define and train the model\n",
    "# kernals could be: ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’.              \n",
    "clf = svm.SVC(kernel=\"linear\", C=1000, probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy info\n",
    "print(\"accuracy train : \", clf.score(X_train, y_train))\n",
    "print(\"accuracy test : \", clf.score(X_test, y_test))\n",
    "print(\"predicted probabilities:\\n\", clf.predict_proba(X_test))\n",
    "\n",
    "##############################  PREDICIOTN  ##############################################\n",
    "# load data set\n",
    "new_data = pd.read_csv(\"DEMO.csv\")\n",
    "\n",
    "# No stroke column so get rid of it\n",
    "new_data = new_data.drop(columns=['stroke'])\n",
    "\n",
    "# get attributes\n",
    "X_new = new_data[featurenames]\n",
    "\n",
    "# impute and scale the data\n",
    "X_new = preprocessing_pipeline.fit_transform(X_new)\n",
    "\n",
    "# Make predictions on the new data, run model\n",
    "new_probabilities = clf.predict_proba(X_new)[:, 0]  # for output\n",
    "new_predictions = clf.predict(X_new) # unsed, just for testing ratio of MI/noMI\n",
    "\n",
    "# Get each sample's ID and write probabilities to the output CSV\n",
    "new_participant_ids = new_data['SEQN']\n",
    "new_output_df = pd.DataFrame({'SEQN': new_participant_ids, 'Pred_Probability': new_probabilities})\n",
    "new_output_df.to_csv('SVMpred.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73ada6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T01:19:43.968502Z",
     "iopub.status.busy": "2024-03-19T01:19:43.968267Z",
     "iopub.status.idle": "2024-03-19T01:19:43.972926Z",
     "shell.execute_reply": "2024-03-19T01:19:43.972370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf support vectors: [[-1.125 -1.015 1.225 ... 0.557 0.540 -0.348]\n",
      " [0.000 0.985 -0.495 ... -1.794 0.540 -0.348]\n",
      " [-0.943 0.985 -1.068 ... 0.557 0.540 -0.348]\n",
      " ...\n",
      " [0.074 0.985 0.733 ... 0.557 0.540 -0.348]\n",
      " [-0.155 0.985 -0.086 ... -1.794 0.540 -0.348]\n",
      " [-0.903 -1.015 0.570 ... 0.557 0.540 2.882]]\n",
      "clf support vector indices: [  0  13  14  15  19  22  24  32  34  37  39  40  43  46  52  53  57  61\n",
      "  62  63  64  67  74  81  82  85  88  89  93  97  99 100 110 112 113 115\n",
      " 123 125 132 133 134   2   3   5   6  12  16  17  31  38  41  42  45  48\n",
      "  51  58  59  60  66  73  75  76  77  87  92  94 103 106 108 109 118 119\n",
      " 121 122 124 127 129]\n",
      "clf # of support vectors in each class: [41 36]\n"
     ]
    }
   ],
   "source": [
    "#### See which data points are critical #####\n",
    "# get the support vectors\n",
    "print(\"clf support vectors: {}\".format(clf.support_vectors_))\n",
    "# get indices of support vectors\n",
    "print(\"clf support vector indices: {}\".format(clf.support_))\n",
    "# get number of support vectors for each class\n",
    "print(\"clf # of support vectors in each class: {}\".format(clf.n_support_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
