{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10eb7d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T01:19:34.727464Z",
     "iopub.status.busy": "2024-03-19T01:19:34.726779Z",
     "iopub.status.idle": "2024-03-19T01:19:35.301271Z",
     "shell.execute_reply": "2024-03-19T01:19:35.300628Z"
    }
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "# Support vector machines (SVMs) are a set of supervised learning methods used for \n",
    "# classification, regression and outliers detection.\n",
    "\n",
    "# The advantages of support vector machines are:\n",
    "    # Effective in high dimensional spaces.\n",
    "    # Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "    # Uses a subset of training points in the decision function (called support vectors), \n",
    "    # so it is also memory efficient.\n",
    "    # Versatile: different Kernel functions can be specified for the decision function. \n",
    "    # Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "# The disadvantages of support vector machines include:\n",
    "    # If the number of features is much greater than the number of samples, avoid over-fitting \n",
    "    # in choosing Kernel functions and regularization term is crucial.\n",
    "    # SVMs do not directly provide probability estimates, these are calculated using an \n",
    "    # expensive five-fold cross-validation (see Scores and probabilities, below).\n",
    "\n",
    "# class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', \n",
    "# coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, \n",
    "# class_weight=None, verbose=False, max_iter=-1, \n",
    "# decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c89a952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T01:19:35.304068Z",
     "iopub.status.busy": "2024-03-19T01:19:35.303737Z",
     "iopub.status.idle": "2024-03-19T01:19:43.966014Z",
     "shell.execute_reply": "2024-03-19T01:19:43.965367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train :  0.7925925925925926\n",
      "accuracy test :  0.6666666666666666\n",
      "predicted probabilities:\n",
      " [[0.765 0.235]\n",
      " [0.303 0.697]\n",
      " [0.161 0.839]\n",
      " [0.469 0.531]\n",
      " [0.838 0.162]\n",
      " [0.238 0.762]\n",
      " [0.318 0.682]\n",
      " [0.795 0.205]\n",
      " [0.173 0.827]\n",
      " [0.245 0.755]\n",
      " [0.750 0.250]\n",
      " [0.263 0.737]\n",
      " [0.749 0.251]\n",
      " [0.704 0.296]\n",
      " [0.257 0.743]\n",
      " [0.394 0.606]\n",
      " [0.254 0.746]\n",
      " [0.221 0.779]\n",
      " [0.367 0.633]\n",
      " [0.580 0.420]\n",
      " [0.149 0.851]\n",
      " [0.338 0.662]\n",
      " [0.834 0.166]\n",
      " [0.510 0.490]\n",
      " [0.572 0.428]\n",
      " [0.798 0.202]\n",
      " [0.857 0.143]\n",
      " [0.791 0.209]\n",
      " [0.836 0.164]\n",
      " [0.607 0.393]\n",
      " [0.561 0.439]\n",
      " [0.440 0.560]\n",
      " [0.245 0.755]\n",
      " [0.865 0.135]\n",
      " [0.162 0.838]\n",
      " [0.463 0.537]\n",
      " [0.602 0.398]\n",
      " [0.553 0.447]\n",
      " [0.512 0.488]\n",
      " [0.227 0.773]\n",
      " [0.805 0.195]\n",
      " [0.614 0.386]\n",
      " [0.212 0.788]\n",
      " [0.613 0.387]\n",
      " [0.798 0.202]\n",
      " [0.800 0.200]\n",
      " [0.438 0.562]\n",
      " [0.446 0.554]\n",
      " [0.598 0.402]\n",
      " [0.317 0.683]\n",
      " [0.164 0.836]\n",
      " [0.603 0.397]\n",
      " [0.278 0.722]\n",
      " [0.104 0.896]\n",
      " [0.755 0.245]\n",
      " [0.469 0.531]\n",
      " [0.275 0.725]\n",
      " [0.481 0.519]\n",
      " [0.260 0.740]\n",
      " [0.339 0.661]\n",
      " [0.535 0.465]\n",
      " [0.434 0.566]\n",
      " [0.633 0.367]\n",
      " [0.534 0.466]\n",
      " [0.509 0.491]\n",
      " [0.195 0.805]\n",
      " [0.300 0.700]\n",
      " [0.772 0.228]\n",
      " [0.091 0.909]\n",
      " [0.756 0.244]\n",
      " [0.650 0.350]\n",
      " [0.585 0.415]\n",
      " [0.742 0.258]\n",
      " [0.328 0.672]\n",
      " [0.745 0.255]\n",
      " [0.669 0.331]\n",
      " [0.689 0.311]\n",
      " [0.617 0.383]\n",
      " [0.313 0.687]\n",
      " [0.413 0.587]\n",
      " [0.121 0.879]\n",
      " [0.456 0.544]\n",
      " [0.289 0.711]\n",
      " [0.452 0.548]\n",
      " [0.742 0.258]\n",
      " [0.705 0.295]\n",
      " [0.756 0.244]\n",
      " [0.655 0.345]\n",
      " [0.500 0.500]\n",
      " [0.748 0.252]\n",
      " [0.213 0.787]\n",
      " [0.373 0.627]\n",
      " [0.826 0.174]\n",
      " [0.185 0.815]\n",
      " [0.789 0.211]\n",
      " [0.471 0.529]\n",
      " [0.548 0.452]\n",
      " [0.398 0.602]\n",
      " [0.736 0.264]\n",
      " [0.250 0.750]\n",
      " [0.527 0.473]\n",
      " [0.637 0.363]\n",
      " [0.754 0.246]\n",
      " [0.785 0.215]\n",
      " [0.398 0.602]\n",
      " [0.141 0.859]\n",
      " [0.178 0.822]\n",
      " [0.613 0.387]\n",
      " [0.552 0.448]\n",
      " [0.577 0.423]\n",
      " [0.521 0.479]\n",
      " [0.553 0.447]\n",
      " [0.032 0.968]\n",
      " [0.184 0.816]\n",
      " [0.398 0.602]\n",
      " [0.500 0.500]\n",
      " [0.722 0.278]\n",
      " [0.370 0.630]\n",
      " [0.064 0.936]\n",
      " [0.645 0.355]\n",
      " [0.709 0.291]\n",
      " [0.178 0.822]\n",
      " [0.534 0.466]\n",
      " [0.682 0.318]\n",
      " [0.593 0.407]\n",
      " [0.659 0.341]\n",
      " [0.456 0.544]\n",
      " [0.511 0.489]\n",
      " [0.677 0.323]\n",
      " [0.753 0.247]\n",
      " [0.281 0.719]\n",
      " [0.798 0.202]\n",
      " [0.587 0.413]\n",
      " [0.618 0.382]\n",
      " [0.500 0.500]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values\n",
    "    ('scaler', StandardScaler())  # Scale the features\n",
    "])\n",
    "\n",
    "# define the SVM model\n",
    "# kernals could be: ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’.              \n",
    "clf = svm.SVC(kernel=\"linear\", C=5000, probability=True)\n",
    "\n",
    "##############################  TRAINING  ##############################################\n",
    "# data\n",
    "input_df = pd.read_csv('NHANES_data_stroke_train.csv')\n",
    "\n",
    "# Under sample the non-stroke\n",
    "# Due to the large number of MI_positive, drop any with missing values, MI_negative will be imputed later\n",
    "MI_positive = input_df[input_df['stroke'] == 1]\n",
    "MI_negative = input_df[input_df['stroke'] == 2]\n",
    "MI_negative.dropna()\n",
    "MI_negative = MI_negative.sample(n=len(MI_positive), replace=False)\n",
    "input_df = pd.concat([MI_positive, MI_negative])\n",
    "\n",
    "# attributes\n",
    "featurenames = [\"Income\",\"Sex\",\"Age\",\"Race\",\"Edu\",\"Diastolic\",\"Systolic\",\"Pulse\",\"BMI\",\"HDL\",\"Trig\",\"LDL\",\"TCHOL\",\"kidneys_eGFR\",\"Diabetes\",\"CurrentSmoker\",\"isActive\",\"isInsured\"]\n",
    "X = input_df[featurenames]\n",
    "y = input_df['stroke']\n",
    "\n",
    "# impute and scale the data\n",
    "X = preprocessing_pipeline.fit_transform(X)\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.50, random_state=42)\n",
    "\n",
    "# train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy info\n",
    "print(\"accuracy train : \", clf.score(X_train, y_train))\n",
    "print(\"accuracy test : \", clf.score(X_test, y_test))\n",
    "print(\"predicted probabilities:\\n\", clf.predict_proba(X_test))\n",
    "\n",
    "##############################  PREDICTION  ##############################################\n",
    "# load data set\n",
    "new_data = pd.read_csv(\"NHANES_data_stroke_test4Students.csv\")\n",
    "\n",
    "# No stroke column so get rid of it\n",
    "new_data = new_data.drop(columns=['stroke'])\n",
    "\n",
    "# get attributes\n",
    "X_new = new_data[featurenames]\n",
    "\n",
    "# impute and scale the data\n",
    "X_new = preprocessing_pipeline.fit_transform(X_new)\n",
    "\n",
    "# Make predictions on the new data, run model\n",
    "new_probabilities = clf.predict_proba(X_new)[:, 0]  # for output\n",
    "new_predictions = clf.predict(X_new) # unsed, just for testing ratio of MI/noMI\n",
    "\n",
    "# Get each sample's ID and write probabilities to the output CSV\n",
    "new_participant_ids = new_data['ParticipantID']\n",
    "new_output_df = pd.DataFrame({'ParticipantID': new_participant_ids, 'Pred_Probability': new_probabilities})\n",
    "new_output_df.to_csv('SVMpred.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73ada6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T01:19:43.968502Z",
     "iopub.status.busy": "2024-03-19T01:19:43.968267Z",
     "iopub.status.idle": "2024-03-19T01:19:43.972926Z",
     "shell.execute_reply": "2024-03-19T01:19:43.972370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf support vectors: [[-1.125 -1.015 1.225 ... 0.557 0.540 -0.348]\n",
      " [0.000 0.985 -0.495 ... -1.794 0.540 -0.348]\n",
      " [-0.943 0.985 -1.068 ... 0.557 0.540 -0.348]\n",
      " ...\n",
      " [0.074 0.985 0.733 ... 0.557 0.540 -0.348]\n",
      " [-0.155 0.985 -0.086 ... -1.794 0.540 -0.348]\n",
      " [-0.903 -1.015 0.570 ... 0.557 0.540 2.882]]\n",
      "clf support vector indices: [  0  13  14  15  19  22  24  32  34  37  39  40  43  46  52  53  57  61\n",
      "  62  63  64  67  74  81  82  85  88  89  93  97  99 100 110 112 113 115\n",
      " 123 125 132 133 134   2   3   5   6  12  16  17  31  38  41  42  45  48\n",
      "  51  58  59  60  66  73  75  76  77  87  92  94 103 106 108 109 118 119\n",
      " 121 122 124 127 129]\n",
      "clf # of support vectors in each class: [41 36]\n"
     ]
    }
   ],
   "source": [
    "#### See which data points are critical #####\n",
    "# get the support vectors\n",
    "print(\"clf support vectors: {}\".format(clf.support_vectors_))\n",
    "# get indices of support vectors\n",
    "print(\"clf support vector indices: {}\".format(clf.support_))\n",
    "# get number of support vectors for each class\n",
    "print(\"clf # of support vectors in each class: {}\".format(clf.n_support_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
