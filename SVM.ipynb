{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10eb7d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T01:19:34.727464Z",
     "iopub.status.busy": "2024-03-19T01:19:34.726779Z",
     "iopub.status.idle": "2024-03-19T01:19:35.301271Z",
     "shell.execute_reply": "2024-03-19T01:19:35.300628Z"
    }
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "# Support vector machines (SVMs) are a set of supervised learning methods used for \n",
    "# classification, regression and outliers detection.\n",
    "\n",
    "# The advantages of support vector machines are:\n",
    "    # Effective in high dimensional spaces.\n",
    "    # Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "    # Uses a subset of training points in the decision function (called support vectors), \n",
    "    # so it is also memory efficient.\n",
    "    # Versatile: different Kernel functions can be specified for the decision function. \n",
    "    # Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "# The disadvantages of support vector machines include:\n",
    "    # If the number of features is much greater than the number of samples, avoid over-fitting \n",
    "    # in choosing Kernel functions and regularization term is crucial.\n",
    "    # SVMs do not directly provide probability estimates, these are calculated using an \n",
    "    # expensive five-fold cross-validation (see Scores and probabilities, below).\n",
    "\n",
    "# class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', \n",
    "# coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, \n",
    "# class_weight=None, verbose=False, max_iter=-1, \n",
    "# decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c89a952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T01:19:35.304068Z",
     "iopub.status.busy": "2024-03-19T01:19:35.303737Z",
     "iopub.status.idle": "2024-03-19T01:19:43.966014Z",
     "shell.execute_reply": "2024-03-19T01:19:43.965367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train :  0.8740740740740741\n",
      "accuracy test :  0.7555555555555555\n",
      "predicted probabilities:\n",
      " [[0.846 0.154]\n",
      " [0.507 0.493]\n",
      " [0.056 0.944]\n",
      " [0.313 0.687]\n",
      " [0.091 0.909]\n",
      " [0.573 0.427]\n",
      " [0.381 0.619]\n",
      " [0.650 0.350]\n",
      " [0.646 0.354]\n",
      " [0.220 0.780]\n",
      " [0.255 0.745]\n",
      " [0.213 0.787]\n",
      " [0.028 0.972]\n",
      " [0.936 0.064]\n",
      " [0.741 0.259]\n",
      " [0.850 0.150]\n",
      " [0.373 0.627]\n",
      " [0.900 0.100]\n",
      " [0.254 0.746]\n",
      " [0.842 0.158]\n",
      " [0.045 0.955]\n",
      " [0.205 0.795]\n",
      " [0.908 0.092]\n",
      " [0.939 0.061]\n",
      " [0.253 0.747]\n",
      " [0.878 0.122]\n",
      " [0.839 0.161]\n",
      " [0.311 0.689]\n",
      " [0.906 0.094]\n",
      " [0.912 0.088]\n",
      " [0.770 0.230]\n",
      " [0.762 0.238]\n",
      " [0.260 0.740]\n",
      " [0.849 0.151]\n",
      " [0.388 0.612]\n",
      " [0.234 0.766]\n",
      " [0.894 0.106]\n",
      " [0.736 0.264]\n",
      " [0.640 0.360]\n",
      " [0.677 0.323]\n",
      " [0.964 0.036]\n",
      " [0.833 0.167]\n",
      " [0.462 0.538]\n",
      " [0.541 0.459]\n",
      " [0.876 0.124]\n",
      " [0.029 0.971]\n",
      " [0.235 0.765]\n",
      " [0.173 0.827]\n",
      " [0.916 0.084]\n",
      " [0.296 0.704]\n",
      " [0.082 0.918]\n",
      " [0.666 0.334]\n",
      " [0.024 0.976]\n",
      " [0.070 0.930]\n",
      " [0.916 0.084]\n",
      " [0.322 0.678]\n",
      " [0.062 0.938]\n",
      " [0.222 0.778]\n",
      " [0.113 0.887]\n",
      " [0.820 0.180]\n",
      " [0.423 0.577]\n",
      " [0.745 0.255]\n",
      " [0.018 0.982]\n",
      " [0.783 0.217]\n",
      " [0.595 0.405]\n",
      " [0.110 0.890]\n",
      " [0.135 0.865]\n",
      " [0.467 0.533]\n",
      " [0.160 0.840]\n",
      " [0.896 0.104]\n",
      " [0.776 0.224]\n",
      " [0.831 0.169]\n",
      " [0.184 0.816]\n",
      " [0.123 0.877]\n",
      " [0.172 0.828]\n",
      " [0.775 0.225]\n",
      " [0.725 0.275]\n",
      " [0.524 0.476]\n",
      " [0.056 0.944]\n",
      " [0.237 0.763]\n",
      " [0.812 0.188]\n",
      " [0.843 0.157]\n",
      " [0.303 0.697]\n",
      " [0.113 0.887]\n",
      " [0.394 0.606]\n",
      " [0.760 0.240]\n",
      " [0.956 0.044]\n",
      " [0.596 0.404]\n",
      " [0.041 0.959]\n",
      " [0.500 0.500]\n",
      " [0.264 0.736]\n",
      " [0.039 0.961]\n",
      " [0.151 0.849]\n",
      " [0.143 0.857]\n",
      " [0.079 0.921]\n",
      " [0.739 0.261]\n",
      " [0.842 0.158]\n",
      " [0.789 0.211]\n",
      " [0.899 0.101]\n",
      " [0.579 0.421]\n",
      " [0.568 0.432]\n",
      " [0.549 0.451]\n",
      " [0.811 0.189]\n",
      " [0.781 0.219]\n",
      " [0.420 0.580]\n",
      " [0.044 0.956]\n",
      " [0.736 0.264]\n",
      " [0.715 0.285]\n",
      " [0.696 0.304]\n",
      " [0.815 0.185]\n",
      " [0.151 0.849]\n",
      " [0.570 0.430]\n",
      " [0.027 0.973]\n",
      " [0.143 0.857]\n",
      " [0.032 0.968]\n",
      " [0.630 0.370]\n",
      " [0.900 0.100]\n",
      " [0.359 0.641]\n",
      " [0.287 0.713]\n",
      " [0.699 0.301]\n",
      " [0.563 0.437]\n",
      " [0.098 0.902]\n",
      " [0.750 0.250]\n",
      " [0.356 0.644]\n",
      " [0.391 0.609]\n",
      " [0.263 0.737]\n",
      " [0.115 0.885]\n",
      " [0.807 0.193]\n",
      " [0.756 0.244]\n",
      " [0.573 0.427]\n",
      " [0.429 0.571]\n",
      " [0.935 0.065]\n",
      " [0.657 0.343]\n",
      " [0.172 0.828]\n",
      " [0.270 0.730]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values\n",
    "    ('scaler', StandardScaler())  # Scale the features\n",
    "])\n",
    "\n",
    "# define the SVM model\n",
    "# kernals could be: ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’.              \n",
    "clf = svm.SVC(kernel=\"rbf\", C=.5, probability=True)\n",
    "\n",
    "##############################  TRAINING  ##############################################\n",
    "# data\n",
    "input_df = pd.read_csv('NHANES_data_stroke_train.csv')\n",
    "\n",
    "# Under sample the non-stroke\n",
    "# Due to the large number of MI_negative, drop any with missing values, MI_positive will be imputed later\n",
    "MI_positive = input_df[input_df['stroke'] == 1]\n",
    "MI_negative = input_df[input_df['stroke'] == 2]\n",
    "MI_negative = MI_negative.dropna()\n",
    "MI_negative = MI_negative.sample(n=len(MI_positive), replace=False)\n",
    "input_df = pd.concat([MI_positive, MI_negative])\n",
    "\n",
    "# attributes\n",
    "featurenames = [\"Income\",\"Age\",\"Race\",\"Diastolic\",\"Systolic\",\"Pulse\",\"BMI\",\"HDL\",\"Trig\",\"LDL\",\"TCHOL\",\"kidneys_eGFR\",\"Diabetes\"]\n",
    "X = input_df[featurenames]\n",
    "y = input_df['stroke']\n",
    "\n",
    "# impute and scale the data\n",
    "X = preprocessing_pipeline.fit_transform(X)\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.50, random_state=42)\n",
    "\n",
    "# train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy info\n",
    "print(\"accuracy train : \", clf.score(X_train, y_train))\n",
    "print(\"accuracy test : \", clf.score(X_test, y_test))\n",
    "print(\"predicted probabilities:\\n\", clf.predict_proba(X_test))\n",
    "\n",
    "##############################  PREDICTION  ##############################################\n",
    "# load data set\n",
    "new_data = pd.read_csv(\"NHANES_data_stroke_test4Students.csv\")\n",
    "\n",
    "# No stroke column so get rid of it\n",
    "new_data = new_data.drop(columns=['stroke'])\n",
    "\n",
    "# get attributes\n",
    "X_new = new_data[featurenames]\n",
    "\n",
    "# impute and scale the data\n",
    "X_new = preprocessing_pipeline.fit_transform(X_new)\n",
    "\n",
    "# Make predictions on the new data, run model\n",
    "new_probabilities = clf.predict_proba(X_new)[:, 0]  # for output\n",
    "new_predictions = clf.predict(X_new) # unsed, just for testing ratio of MI/noMI\n",
    "\n",
    "# Get each sample's ID and write probabilities to the output CSV\n",
    "new_participant_ids = new_data['ParticipantID']\n",
    "new_output_df = pd.DataFrame({'ParticipantID': new_participant_ids, 'Pred_Probability': new_probabilities})\n",
    "new_output_df.to_csv('SVMpred.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73ada6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T01:19:43.968502Z",
     "iopub.status.busy": "2024-03-19T01:19:43.968267Z",
     "iopub.status.idle": "2024-03-19T01:19:43.972926Z",
     "shell.execute_reply": "2024-03-19T01:19:43.972370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf support vectors: [[-1.125 -1.015 1.225 ... 0.557 0.540 -0.348]\n",
      " [0.000 0.985 -0.495 ... -1.794 0.540 -0.348]\n",
      " [-0.943 0.985 -1.068 ... 0.557 0.540 -0.348]\n",
      " ...\n",
      " [0.074 0.985 0.733 ... 0.557 0.540 -0.348]\n",
      " [-0.155 0.985 -0.086 ... -1.794 0.540 -0.348]\n",
      " [-0.903 -1.015 0.570 ... 0.557 0.540 2.882]]\n",
      "clf support vector indices: [  0  13  14  15  19  22  24  32  34  37  39  40  43  46  52  53  57  61\n",
      "  62  63  64  67  74  81  82  85  88  89  93  97  99 100 110 112 113 115\n",
      " 123 125 132 133 134   2   3   5   6  12  16  17  31  38  41  42  45  48\n",
      "  51  58  59  60  66  73  75  76  77  87  92  94 103 106 108 109 118 119\n",
      " 121 122 124 127 129]\n",
      "clf # of support vectors in each class: [41 36]\n"
     ]
    }
   ],
   "source": [
    "#### See which data points are critical #####\n",
    "# get the support vectors\n",
    "print(\"clf support vectors: {}\".format(clf.support_vectors_))\n",
    "# get indices of support vectors\n",
    "print(\"clf support vector indices: {}\".format(clf.support_))\n",
    "# get number of support vectors for each class\n",
    "print(\"clf # of support vectors in each class: {}\".format(clf.n_support_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
