{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10eb7d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T01:19:34.727464Z",
     "iopub.status.busy": "2024-03-19T01:19:34.726779Z",
     "iopub.status.idle": "2024-03-19T01:19:35.301271Z",
     "shell.execute_reply": "2024-03-19T01:19:35.300628Z"
    }
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "# Support vector machines (SVMs) are a set of supervised learning methods used for \n",
    "# classification, regression and outliers detection.\n",
    "\n",
    "# The advantages of support vector machines are:\n",
    "    # Effective in high dimensional spaces.\n",
    "    # Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "    # Uses a subset of training points in the decision function (called support vectors), \n",
    "    # so it is also memory efficient.\n",
    "    # Versatile: different Kernel functions can be specified for the decision function. \n",
    "    # Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "# The disadvantages of support vector machines include:\n",
    "    # If the number of features is much greater than the number of samples, avoid over-fitting \n",
    "    # in choosing Kernel functions and regularization term is crucial.\n",
    "    # SVMs do not directly provide probability estimates, these are calculated using an \n",
    "    # expensive five-fold cross-validation (see Scores and probabilities, below).\n",
    "\n",
    "# class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', \n",
    "# coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, \n",
    "# class_weight=None, verbose=False, max_iter=-1, \n",
    "# decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c89a952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T01:19:35.304068Z",
     "iopub.status.busy": "2024-03-19T01:19:35.303737Z",
     "iopub.status.idle": "2024-03-19T01:19:43.966014Z",
     "shell.execute_reply": "2024-03-19T01:19:43.965367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train :  0.7777777777777778\n",
      "accuracy test :  0.6518518518518519\n",
      "predicted probabilities:\n",
      " [[0.724 0.276]\n",
      " [0.483 0.517]\n",
      " [0.298 0.702]\n",
      " [0.331 0.669]\n",
      " [0.548 0.452]\n",
      " [0.350 0.650]\n",
      " [0.360 0.640]\n",
      " [0.631 0.369]\n",
      " [0.514 0.486]\n",
      " [0.387 0.613]\n",
      " [0.506 0.494]\n",
      " [0.294 0.706]\n",
      " [0.555 0.445]\n",
      " [0.592 0.408]\n",
      " [0.140 0.860]\n",
      " [0.416 0.584]\n",
      " [0.298 0.702]\n",
      " [0.828 0.172]\n",
      " [0.486 0.514]\n",
      " [0.401 0.599]\n",
      " [0.312 0.688]\n",
      " [0.477 0.523]\n",
      " [0.695 0.305]\n",
      " [0.551 0.449]\n",
      " [0.252 0.748]\n",
      " [0.824 0.176]\n",
      " [0.787 0.213]\n",
      " [0.139 0.861]\n",
      " [0.678 0.322]\n",
      " [0.544 0.456]\n",
      " [0.583 0.417]\n",
      " [0.416 0.584]\n",
      " [0.433 0.567]\n",
      " [0.619 0.381]\n",
      " [0.617 0.383]\n",
      " [0.408 0.592]\n",
      " [0.588 0.412]\n",
      " [0.488 0.512]\n",
      " [0.464 0.536]\n",
      " [0.184 0.816]\n",
      " [0.771 0.229]\n",
      " [0.424 0.576]\n",
      " [0.212 0.788]\n",
      " [0.393 0.607]\n",
      " [0.625 0.375]\n",
      " [0.421 0.579]\n",
      " [0.487 0.513]\n",
      " [0.694 0.306]\n",
      " [0.589 0.411]\n",
      " [0.555 0.445]\n",
      " [0.290 0.710]\n",
      " [0.668 0.332]\n",
      " [0.440 0.560]\n",
      " [0.232 0.768]\n",
      " [0.589 0.411]\n",
      " [0.532 0.468]\n",
      " [0.427 0.573]\n",
      " [0.466 0.534]\n",
      " [0.126 0.874]\n",
      " [0.389 0.611]\n",
      " [0.432 0.568]\n",
      " [0.439 0.561]\n",
      " [0.482 0.518]\n",
      " [0.653 0.347]\n",
      " [0.557 0.443]\n",
      " [0.289 0.711]\n",
      " [0.343 0.657]\n",
      " [0.160 0.840]\n",
      " [0.412 0.588]\n",
      " [0.733 0.267]\n",
      " [0.553 0.447]\n",
      " [0.613 0.387]\n",
      " [0.379 0.621]\n",
      " [0.264 0.736]\n",
      " [0.516 0.484]\n",
      " [0.591 0.409]\n",
      " [0.672 0.328]\n",
      " [0.451 0.549]\n",
      " [0.665 0.335]\n",
      " [0.342 0.658]\n",
      " [0.313 0.687]\n",
      " [0.425 0.575]\n",
      " [0.355 0.645]\n",
      " [0.306 0.694]\n",
      " [0.389 0.611]\n",
      " [0.679 0.321]\n",
      " [0.773 0.227]\n",
      " [0.559 0.441]\n",
      " [0.538 0.462]\n",
      " [0.545 0.455]\n",
      " [0.448 0.552]\n",
      " [0.319 0.681]\n",
      " [0.360 0.640]\n",
      " [0.341 0.659]\n",
      " [0.295 0.705]\n",
      " [0.447 0.553]\n",
      " [0.580 0.420]\n",
      " [0.550 0.450]\n",
      " [0.536 0.464]\n",
      " [0.269 0.731]\n",
      " [0.117 0.883]\n",
      " [0.145 0.855]\n",
      " [0.772 0.228]\n",
      " [0.561 0.439]\n",
      " [0.195 0.805]\n",
      " [0.837 0.163]\n",
      " [0.234 0.766]\n",
      " [0.665 0.335]\n",
      " [0.434 0.566]\n",
      " [0.554 0.446]\n",
      " [0.362 0.638]\n",
      " [0.529 0.471]\n",
      " [0.586 0.414]\n",
      " [0.226 0.774]\n",
      " [0.110 0.890]\n",
      " [0.594 0.406]\n",
      " [0.788 0.212]\n",
      " [0.214 0.786]\n",
      " [0.181 0.819]\n",
      " [0.354 0.646]\n",
      " [0.650 0.350]\n",
      " [0.136 0.864]\n",
      " [0.470 0.530]\n",
      " [0.325 0.675]\n",
      " [0.420 0.580]\n",
      " [0.518 0.482]\n",
      " [0.435 0.565]\n",
      " [0.581 0.419]\n",
      " [0.658 0.342]\n",
      " [0.775 0.225]\n",
      " [0.353 0.647]\n",
      " [0.819 0.181]\n",
      " [0.465 0.535]\n",
      " [0.340 0.660]\n",
      " [0.428 0.572]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values\n",
    "    ('scaler', StandardScaler())  # Scale the features\n",
    "])\n",
    "\n",
    "# define and train the model\n",
    "# kernals could be: ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’.              \n",
    "clf = svm.SVC(kernel=\"linear\", C=5000, probability=True)\n",
    "\n",
    "##############################  TRAINING  ##############################################\n",
    "# data\n",
    "input_data = pd.read_csv('NHANES_data_stroke_train.csv')\n",
    "\n",
    "#under sample the non-stroke\n",
    "MI_positive = input_data[input_data['stroke'] == 1]\n",
    "MI_negitive = input_data[input_data['stroke'] == 2].sample(frac=.03411675511751327)\n",
    "input_data = pd.concat([MI_positive, MI_negitive])\n",
    "\n",
    "# attributes\n",
    "featurenames = [\"Income\",\"Sex\",\"Age\",\"Race\",\"Edu\",\"Diastolic\",\"Systolic\",\"Pulse\",\"BMI\",\"HDL\",\"Trig\",\"LDL\",\"TCHOL\",\"kidneys_eGFR\",\"Diabetes\",\"CurrentSmoker\",\"isActive\",\"isInsured\"]\n",
    "X = input_data[featurenames]\n",
    "y = input_data['stroke']\n",
    "\n",
    "# impute and scale the data\n",
    "X = preprocessing_pipeline.fit_transform(X)\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.50, random_state=42)\n",
    "\n",
    "# train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# print accuracy info\n",
    "print(\"accuracy train : \", clf.score(X_train, y_train))\n",
    "print(\"accuracy test : \", clf.score(X_test, y_test))\n",
    "print(\"predicted probabilities:\\n\", clf.predict_proba(X_test))\n",
    "\n",
    "##############################  PREDICTION  ##############################################\n",
    "# load data set\n",
    "new_data = pd.read_csv(\"DEMO.csv\")\n",
    "\n",
    "# No stroke column so get rid of it\n",
    "new_data = new_data.drop(columns=['stroke'])\n",
    "\n",
    "# get attributes\n",
    "X_new = new_data[featurenames]\n",
    "\n",
    "# impute and scale the data\n",
    "X_new = preprocessing_pipeline.fit_transform(X_new)\n",
    "\n",
    "# Make predictions on the new data, run model\n",
    "new_probabilities = clf.predict_proba(X_new)[:, 0]  # for output\n",
    "new_predictions = clf.predict(X_new) # unsed, just for testing ratio of MI/noMI\n",
    "\n",
    "# Get each sample's ID and write probabilities to the output CSV\n",
    "new_participant_ids = new_data['SEQN']\n",
    "new_output_df = pd.DataFrame({'SEQN': new_participant_ids, 'Pred_Probability': new_probabilities})\n",
    "new_output_df.to_csv('SVMpred.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73ada6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T01:19:43.968502Z",
     "iopub.status.busy": "2024-03-19T01:19:43.968267Z",
     "iopub.status.idle": "2024-03-19T01:19:43.972926Z",
     "shell.execute_reply": "2024-03-19T01:19:43.972370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf support vectors: [[-1.125 -1.015 1.225 ... 0.557 0.540 -0.348]\n",
      " [0.000 0.985 -0.495 ... -1.794 0.540 -0.348]\n",
      " [-0.943 0.985 -1.068 ... 0.557 0.540 -0.348]\n",
      " ...\n",
      " [0.074 0.985 0.733 ... 0.557 0.540 -0.348]\n",
      " [-0.155 0.985 -0.086 ... -1.794 0.540 -0.348]\n",
      " [-0.903 -1.015 0.570 ... 0.557 0.540 2.882]]\n",
      "clf support vector indices: [  0  13  14  15  19  22  24  32  34  37  39  40  43  46  52  53  57  61\n",
      "  62  63  64  67  74  81  82  85  88  89  93  97  99 100 110 112 113 115\n",
      " 123 125 132 133 134   2   3   5   6  12  16  17  31  38  41  42  45  48\n",
      "  51  58  59  60  66  73  75  76  77  87  92  94 103 106 108 109 118 119\n",
      " 121 122 124 127 129]\n",
      "clf # of support vectors in each class: [41 36]\n"
     ]
    }
   ],
   "source": [
    "#### See which data points are critical #####\n",
    "# get the support vectors\n",
    "print(\"clf support vectors: {}\".format(clf.support_vectors_))\n",
    "# get indices of support vectors\n",
    "print(\"clf support vector indices: {}\".format(clf.support_))\n",
    "# get number of support vectors for each class\n",
    "print(\"clf # of support vectors in each class: {}\".format(clf.n_support_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
