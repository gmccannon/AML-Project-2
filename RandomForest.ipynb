{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10eb7d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T02:36:26.211899Z",
     "iopub.status.busy": "2024-03-19T02:36:26.211303Z",
     "iopub.status.idle": "2024-03-19T02:36:26.472555Z",
     "shell.execute_reply": "2024-03-19T02:36:26.471868Z"
    }
   },
   "outputs": [],
   "source": [
    "# A random forest is a meta estimator that fits a number of decision tree classifiers on \n",
    "# various sub-samples of the dataset and uses averaging to improve the predictive accuracy \n",
    "# and control over-fitting. The sub-sample size is controlled with the max_samples parameter \n",
    "# if bootstrap=True (default), otherwise the whole dataset is used to build each tree.\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', \n",
    "# max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "# max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, \n",
    "# oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, \n",
    "# class_weight=None, ccp_alpha=0.0, max_samples=None)[source]\n",
    "\n",
    "# to run: $\n",
    "# jupyter nbconvert --to notebook --inplace --execute Project1.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd21db51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T02:36:26.475435Z",
     "iopub.status.busy": "2024-03-19T02:36:26.475169Z",
     "iopub.status.idle": "2024-03-19T02:36:32.132439Z",
     "shell.execute_reply": "2024-03-19T02:36:32.131777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train: 79.20792079207921\n",
      "Accuracy for test 10: 75.0\n",
      "Accuracy for train: 80.19801980198021\n",
      "Accuracy for test 10: 72.05882352941177\n",
      "Accuracy for train: 81.1881188118812\n",
      "Accuracy for test 10: 73.52941176470588\n",
      "Accuracy for train: 77.22772277227723\n",
      "Accuracy for test 10: 80.88235294117648\n",
      "* Average accuracy for all tests *: 75.36764705882354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define the RandomForestClassifier with tuned hyperparameters\n",
    "clf = RandomForestClassifier(n_estimators=2000, max_depth=2, criterion='gini', min_samples_split=2, min_samples_leaf=2)\n",
    "\n",
    "##############################  TRAINING  ##############################################\n",
    "# Load dataset\n",
    "input_df = pd.read_csv(\"NHANES_data_stroke_train.csv\")\n",
    "\n",
    "# Under sample the non-stroke\n",
    "MI_positive = input_df[input_df['stroke'] == 1]\n",
    "MI_negative = input_df[input_df['stroke'] == 2].sample(frac=.03411675511751327)\n",
    "input_df = pd.concat([MI_positive, MI_negative])\n",
    "\n",
    "# define attributes\n",
    "featurenames = [\"Income\",\"Sex\",\"Age\",\"Race\",\"Edu\",\"Diastolic\",\"Systolic\",\"Pulse\",\"BMI\",\"HDL\",\"Trig\",\"LDL\",\"TCHOL\",\"kidneys_eGFR\",\"Diabetes\",\"CurrentSmoker\",\"isActive\",\"isInsured\"]\n",
    "X = input_df[featurenames]\n",
    "y = input_df[\"stroke\"]\n",
    "\n",
    "# impute and scale the data\n",
    "X = preprocessing_pipeline.fit_transform(X)\n",
    "\n",
    "avgAccuracy = []\n",
    "while True:\n",
    "    # split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "    # train the model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Print train and test accuracies\n",
    "    print(\"Accuracy for train:\", clf.score(X_train, y_train)*100)\n",
    "    acc = clf.score(X_test, y_test)*100\n",
    "    avgAccuracy.append(acc)\n",
    "    print(f\"Accuracy for test:\", acc)\n",
    "\n",
    "    if acc >= 76:\n",
    "        break\n",
    "\n",
    "# Print average accuracy across all tests\n",
    "print(\"* Average accuracy for all tests *:\", np.mean(avgAccuracy))\n",
    "\n",
    "##############################  PREDICTION  ##############################################\n",
    "# load data set\n",
    "new_data = pd.read_csv(\"DEMO.csv\")\n",
    "\n",
    "# No stroke column so get rid of it\n",
    "new_data = new_data.drop(columns=['stroke'])\n",
    "\n",
    "# get attributes\n",
    "X_new = new_data[featurenames]\n",
    "\n",
    "# imputer\n",
    "X_new = preprocessing_pipeline.fit_transform(X_new)\n",
    "\n",
    "# Make predictions on the new data, run model\n",
    "new_probabilities = clf.predict_proba(X_new)[:, 0]  # for output\n",
    "new_predictions = clf.predict(X_new) # unsed, just for testing ratio of MI/noMI\n",
    "\n",
    "# Get each sample's ID and write probabilities to the output CSV\n",
    "new_participant_ids = new_data['SEQN']\n",
    "new_output_df = pd.DataFrame({'SEQN': new_participant_ids, 'Pred_Probability': new_probabilities})\n",
    "new_output_df.to_csv('RFPred.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c81f7324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T02:36:32.135175Z",
     "iopub.status.busy": "2024-03-19T02:36:32.134939Z",
     "iopub.status.idle": "2024-03-19T02:36:32.185288Z",
     "shell.execute_reply": "2024-03-19T02:36:32.184706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for train: 80.19801980198021\n",
      "\n",
      "           Feature  Importance\n",
      "13   kidneys_eGFR    0.237421\n",
      "2             Age    0.202963\n",
      "9             HDL    0.086621\n",
      "6        Systolic    0.079742\n",
      "12          TCHOL    0.076883\n",
      "8             BMI    0.067023\n",
      "0          Income    0.059013\n",
      "3            Race    0.057709\n",
      "11            LDL    0.035392\n",
      "10           Trig    0.033668\n",
      "14       Diabetes    0.019218\n",
      "5       Diastolic    0.016505\n",
      "7           Pulse    0.015389\n",
      "15  CurrentSmoker    0.004574\n",
      "4             Edu    0.004267\n",
      "16       isActive    0.002290\n",
      "17      isInsured    0.001003\n",
      "1             Sex    0.000320\n"
     ]
    }
   ],
   "source": [
    "# feature importance\n",
    "print(\"accuracy for train:\", clf.score(X_train, y_train)*100)\n",
    "\n",
    "# ranked based on the average impurity decrease across all the decision trees in the forest\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display the feature importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': featurenames, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\n\", feature_importance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
