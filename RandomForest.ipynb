{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10eb7d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T02:36:26.211899Z",
     "iopub.status.busy": "2024-03-19T02:36:26.211303Z",
     "iopub.status.idle": "2024-03-19T02:36:26.472555Z",
     "shell.execute_reply": "2024-03-19T02:36:26.471868Z"
    }
   },
   "outputs": [],
   "source": [
    "# A random forest is a meta estimator that fits a number of decision tree classifiers on \n",
    "# various sub-samples of the dataset and uses averaging to improve the predictive accuracy \n",
    "# and control over-fitting. The sub-sample size is controlled with the max_samples parameter \n",
    "# if bootstrap=True (default), otherwise the whole dataset is used to build each tree.\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', \n",
    "# max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "# max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, \n",
    "# oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, \n",
    "# class_weight=None, ccp_alpha=0.0, max_samples=None)[source]\n",
    "\n",
    "# to run: $\n",
    "# jupyter nbconvert --to notebook --inplace --execute Project1.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd21db51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T02:36:26.475435Z",
     "iopub.status.busy": "2024-03-19T02:36:26.475169Z",
     "iopub.status.idle": "2024-03-19T02:36:32.132439Z",
     "shell.execute_reply": "2024-03-19T02:36:32.131777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Average accuracy for test 0 *: 67.64705882352942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Average accuracy for test 1 *: 63.235294117647065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Average accuracy for test 2 *: 63.235294117647065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Average accuracy for test 3 *: 66.1764705882353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Average accuracy for test 4 *: 64.70588235294119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Average accuracy for test 5 *: 65.19607843137256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Average accuracy for test 6 *: 63.655462184873954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Average accuracy for test 7 *: 63.602941176470594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Average accuracy for test 8 *: 63.72549019607844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Average accuracy for test 9 *: 63.52941176470589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from random import randint\n",
    "\n",
    "#input dataset\n",
    "fruit_df = pd.read_csv(\"NHANES_data_stroke_train.csv\")\n",
    "\n",
    "#under sample the non-stroke\n",
    "MI_positive = fruit_df[fruit_df['stroke'] == 1]\n",
    "MI_negitive = fruit_df[fruit_df['stroke'] == 2].sample(frac=.03411675511751327)\n",
    "fruit_df = pd.concat([MI_positive, MI_negitive])\n",
    "\n",
    "fruit_featureNames = [\"Income\",\"Sex\",\"Age\",\"Systolic\",\"BMI\",\"HDL\",\"TCHOL\",\"kidneys_eGFR\"]\n",
    "X = fruit_df[fruit_featureNames]\n",
    "y = fruit_df[\"stroke\"]\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "X = preprocessing_pipeline.fit_transform(X)\n",
    "\n",
    "#add features\n",
    "\n",
    "\n",
    "avgAccuracy = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "    # n_estimators = 100 <--- # of trees\n",
    "    clf = RandomForestClassifier(n_estimators=500, max_depth=12, criterion='gini')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #print(\"accuracy for train:\", clf.score(X_train, y_train)*100)\n",
    "    acc = clf.score(X_test, y_test)*100\n",
    "    avgAccuracy = avgAccuracy+[acc]\n",
    "    # print(f\"accuracy for test {i + 1}...... \", acc)\n",
    "\n",
    "    print(f\"* Average accuracy for test {i} *: {sum(avgAccuracy)/len(avgAccuracy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81f7324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T02:36:32.135175Z",
     "iopub.status.busy": "2024-03-19T02:36:32.134939Z",
     "iopub.status.idle": "2024-03-19T02:36:32.185288Z",
     "shell.execute_reply": "2024-03-19T02:36:32.184706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for train: 100.0\n",
      "\n",
      "         Feature  Importance\n",
      "7  kidneys_eGFR    0.188595\n",
      "3      Systolic    0.161606\n",
      "2           Age    0.152292\n",
      "6         TCHOL    0.144194\n",
      "4           BMI    0.114164\n",
      "0        Income    0.111462\n",
      "5           HDL    0.110881\n",
      "1           Sex    0.016806\n"
     ]
    }
   ],
   "source": [
    "# feature importance\n",
    "print(\"accuracy for train:\", clf.score(X_train, y_train)*100)\n",
    "\n",
    "# ranked based on the average impurity decrease across all the decision trees in the forest\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display the feature importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': fruit_featureNames, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\n\", feature_importance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
