{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10eb7d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T02:36:26.211899Z",
     "iopub.status.busy": "2024-03-19T02:36:26.211303Z",
     "iopub.status.idle": "2024-03-19T02:36:26.472555Z",
     "shell.execute_reply": "2024-03-19T02:36:26.471868Z"
    }
   },
   "outputs": [],
   "source": [
    "# A random forest is a meta estimator that fits a number of decision tree classifiers on \n",
    "# various sub-samples of the dataset and uses averaging to improve the predictive accuracy \n",
    "# and control over-fitting. The sub-sample size is controlled with the max_samples parameter \n",
    "# if bootstrap=True (default), otherwise the whole dataset is used to build each tree.\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "# class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', \n",
    "# max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "# max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, \n",
    "# oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, \n",
    "# class_weight=None, ccp_alpha=0.0, max_samples=None)[source]\n",
    "\n",
    "# to run: $\n",
    "# jupyter nbconvert --to notebook --inplace --execute Project1.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd21db51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T02:36:26.475435Z",
     "iopub.status.busy": "2024-03-19T02:36:26.475169Z",
     "iopub.status.idle": "2024-03-19T02:36:32.132439Z",
     "shell.execute_reply": "2024-03-19T02:36:32.131777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train: 80.6930693069307\n",
      "Accuracy for test 1: 79.41176470588235\n",
      "Accuracy for train: 80.19801980198021\n",
      "Accuracy for test 2: 77.94117647058823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "##############################  TRAINING  ##############################################\n",
    "# Load dataset\n",
    "input_df = pd.read_csv(\"NHANES_data_stroke_train.csv\")\n",
    "\n",
    "# Under sample the non-stroke\n",
    "MI_positive = input_df[input_df['stroke'] == 1]\n",
    "MI_negative = input_df[input_df['stroke'] == 2].sample(frac=.03411675511751327)\n",
    "input_df = pd.concat([MI_positive, MI_negative])\n",
    "\n",
    "featurenames = [\"Income\",\"Sex\",\"Age\",\"Race\",\"Edu\",\"Diastolic\",\"Systolic\",\"Pulse\",\"BMI\",\"HDL\",\"Trig\",\"LDL\",\"TCHOL\",\"kidneys_eGFR\",\"Diabetes\",\"CurrentSmoker\",\"isActive\",\"isInsured\"]\n",
    "\n",
    "X = input_df[featurenames]\n",
    "y = input_df[\"stroke\"]\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "X = preprocessing_pipeline.fit_transform(X)\n",
    "\n",
    "avgAccuracy = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "    # Define the RandomForestClassifier with tuned hyperparameters\n",
    "    clf = RandomForestClassifier(n_estimators=500, max_depth=2, criterion='gini', min_samples_split=2, min_samples_leaf=2)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Print train and test accuracies\n",
    "    print(\"Accuracy for train:\", clf.score(X_train, y_train)*100)\n",
    "    acc = clf.score(X_test, y_test)*100\n",
    "    avgAccuracy.append(acc)\n",
    "    print(f\"Accuracy for test {i + 1}:\", acc)\n",
    "\n",
    "# Print average accuracy across all tests\n",
    "print(\"* Average accuracy for all tests *:\", np.mean(avgAccuracy))\n",
    "\n",
    "##############################  PREDICIOTN  ##############################################\n",
    "# load data set\n",
    "new_data = pd.read_csv(\"DEMO.csv\")\n",
    "\n",
    "# No stroke column so get rid of it\n",
    "new_data = new_data.drop(columns=['stroke'])\n",
    "\n",
    "# get attributes\n",
    "X_new = new_data[featurenames]\n",
    "\n",
    "# imputer\n",
    "X_new = preprocessing_pipeline.fit_transform(X_new)\n",
    "\n",
    "# Make predictions on the new data, run model\n",
    "new_probabilities = clf.predict_proba(X_new)[:, 0]  # for output\n",
    "new_predictions = clf.predict(X_new) # unsed, just for testing ratio of MI/noMI\n",
    "\n",
    "# Get each sample's ID and write probabilities to the output CSV\n",
    "new_participant_ids = new_data['SEQN']\n",
    "new_output_df = pd.DataFrame({'SEQN': new_participant_ids, 'Pred_Probability': new_probabilities})\n",
    "new_output_df.to_csv('RFPred.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81f7324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T02:36:32.135175Z",
     "iopub.status.busy": "2024-03-19T02:36:32.134939Z",
     "iopub.status.idle": "2024-03-19T02:36:32.185288Z",
     "shell.execute_reply": "2024-03-19T02:36:32.184706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for train: 100.0\n",
      "\n",
      "         Feature  Importance\n",
      "7  kidneys_eGFR    0.184314\n",
      "2           Age    0.170259\n",
      "0        Income    0.159905\n",
      "3      Systolic    0.128499\n",
      "6         TCHOL    0.123687\n",
      "4           BMI    0.113949\n",
      "5           HDL    0.103187\n",
      "1           Sex    0.016200\n"
     ]
    }
   ],
   "source": [
    "# feature importance\n",
    "print(\"accuracy for train:\", clf.score(X_train, y_train)*100)\n",
    "\n",
    "# ranked based on the average impurity decrease across all the decision trees in the forest\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display the feature importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': featurenames, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\n\", feature_importance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
